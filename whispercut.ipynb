{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXrBuvDjq4v1"
      },
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/cyremur/whispercut/blob/main/whispercut.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All the config variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxbALoy6q3Bf"
      },
      "outputs": [],
      "source": [
        "WHISPERDIR = \"/content/drive/MyDrive/whispercut\"\n",
        "INPUTDIR = f\"{WHISPERDIR}/input\"\n",
        "WORKDIR = f\"{WHISPERDIR}/workdir\"\n",
        "OUTPUTDIR = f\"{WHISPERDIR}/output\"\n",
        "ARCHIVEDIR = f\"{WHISPERDIR}/archive\"\n",
        "\n",
        "START_PHRASES = [\"rant time\"] \n",
        "END_PHRASES = [\"don't leave\", \"not going anywhere\"]\n",
        "EDITOR_PHRASES = [\"editor\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtoEu1cBl381"
      },
      "source": [
        "Check GPU cause why not (Tesla T4 has been fine for me so far)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLihp_mokqu2"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi -L"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDELKnBBlrjo"
      },
      "source": [
        "Connect to Google Drive work folder and pick a video to work on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_1QoGqiFYDWP"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "from google.colab import drive\n",
        "from glob import glob\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "inputfiles = glob(f\"{INPUTDIR}/*\")\n",
        "\n",
        "if len(inputfiles) == 0:\n",
        "  print(\"Please put a video into\", INPUTDIR)\n",
        "  runtime.unassign()\n",
        "\n",
        "# for now, we're gonna trust the user to only but video files into the folder\n",
        "INPUTVIDEO = inputfiles[0]\n",
        "print(\"Processing started for:\", INPUTVIDEO)\n",
        "PROJECTNAME = os.path.basename(INPUTVIDEO).split(\".\")[0]\n",
        "VIDEOFORMAT = os.path.basename(INPUTVIDEO).split(\".\")[1]\n",
        "\n",
        "# setup some directories\n",
        "PROJECTDIR = f'{WORKDIR}/{PROJECTNAME}'\n",
        "os.makedirs(PROJECTDIR, exist_ok=True)\n",
        "RESULTSDIR = f'{OUTPUTDIR}/{PROJECTNAME}'\n",
        "os.makedirs(RESULTSDIR, exist_ok=True)\n",
        "os.makedirs(f'{ARCHIVEDIR}', exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sin_NrUblCft"
      },
      "source": [
        "Let's install whisper ai and ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNIbPOEtlBLH"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git \n",
        "!sudo apt update && sudo apt install ffmpeg\n",
        "!pip install setuptools-rust"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Lp8HVK0m6ws"
      },
      "source": [
        "Convert video to mp3 and feed into whisper ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6-K-IzLRm8Na"
      },
      "outputs": [],
      "source": [
        "!ffmpeg -i $INPUTVIDEO $PROJECTDIR/audio.mp3 -y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NYUl3E3oLqS"
      },
      "outputs": [],
      "source": [
        "!whisper $PROJECTDIR/audio.mp3 --language en --model medium.en -o $PROJECTDIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sn1LSEN_gf9K"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "lines = {}\n",
        "with open(f\"{PROJECTDIR}/audio.mp3.srt\") as f:\n",
        "  while True:\n",
        "    numberOrSpace = f.readline().strip()\n",
        "    if numberOrSpace == \"\":\n",
        "      break\n",
        "    numberOrSpace = int(numberOrSpace)\n",
        "    timestamps = f.readline().strip()\n",
        "    before = timestamps.split(\" \")[0]\n",
        "    after = timestamps.split(\" \")[2]\n",
        "    text = f.readline().strip()\n",
        "    f.readline()\n",
        "    lines[numberOrSpace] = {\"before\": before, \"after\": after, \"text\": text}\n",
        "    print(numberOrSpace, before, after, text)\n",
        "with open(f\"{PROJECTDIR}/lines.json\", \"w\") as f:\n",
        "  json.dump(lines, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrxW5MtJXeqC"
      },
      "source": [
        "Now we go through the lines and find the start and end markers, looking at two lines at a time in case a start phrase wraps over a line break."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cPCDfw0Wrs0"
      },
      "outputs": [],
      "source": [
        "def search_for_phrase(phrase):\n",
        "  results = []\n",
        "\n",
        "  if len(lines.keys()) == 0:\n",
        "    return []\n",
        "  # code dup but saves me set comp later\n",
        "  if phrase.lower() in lines[1][\"text\"]:\n",
        "    # print(1, phrase, lines[1][\"text\"])\n",
        "    results.append({\n",
        "        \"index\": 1, \n",
        "        \"before\": lines[1][\"before\"], \n",
        "        \"after\": lines[1][\"after\"],\n",
        "        \"text\": lines[1][\"text\"]})\n",
        "\n",
        "  for i in range(1, len(lines.keys())):\n",
        "    # search doublelines because activation phrases might be on a line break\n",
        "    first = lines[i]\n",
        "    second = lines[i+1]\n",
        "    doubleline = f'{first[\"text\"]} {second[\"text\"]}'\n",
        "    if phrase.lower() in doubleline.lower():\n",
        "      if phrase.lower() in first[\"text\"].lower():\n",
        "        pass # results appear in `second` before they appear in `first`\n",
        "      elif phrase.lower() in second[\"text\"].lower():\n",
        "        # print(i+1, phrase, second[\"text\"])\n",
        "        results.append({\n",
        "            \"index\": i+1, \n",
        "            \"before\": second[\"before\"], \n",
        "            \"after\": second[\"after\"],\n",
        "            \"text\": second[\"text\"]})\n",
        "      else:\n",
        "        # print(i, \"&\", i+1, phrase, doubleline) \n",
        "        results.append({\n",
        "            \"index\": i + 0.5, \n",
        "            \"before\": first[\"before\"], \n",
        "            \"after\": second[\"after\"],\n",
        "            \"text\": doubleline})\n",
        "  #endfor\n",
        "  return results\n",
        "\n",
        "print(\"Start markers\")\n",
        "start_markers=[]\n",
        "for start_phrase in START_PHRASES:\n",
        "  print(start_phrase)\n",
        "  hits = search_for_phrase(start_phrase)\n",
        "  for hit in hits:\n",
        "    print(hit)\n",
        "    start_markers.append(hit)\n",
        "start_markers.sort(key=lambda x: x[\"index\"])\n",
        "\n",
        "print()\n",
        "print(\"End markers\")\n",
        "end_markers=[]\n",
        "for end_phrase in END_PHRASES:\n",
        "  print(end_phrase)\n",
        "  hits = search_for_phrase(end_phrase)\n",
        "  for hit in hits:\n",
        "    print(hit)\n",
        "    end_markers.append(hit)\n",
        "end_markers.sort(key=lambda x: x[\"index\"])\n",
        "print(end_markers)\n",
        "\n",
        "print()\n",
        "print(\"Editor markers\")\n",
        "editor_markers=[]\n",
        "for editor_phrase in EDITOR_PHRASES:\n",
        "  print(editor_phrase)\n",
        "  hits = search_for_phrase(editor_phrase)\n",
        "  for hit in hits:\n",
        "    print(hit)\n",
        "    editor_markers.append(hit)\n",
        "editor_markers.sort(key=lambda x: x[\"index\"])\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H1vbhHqED2gE"
      },
      "source": [
        "Evaluate the markers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpFan43AD1-9"
      },
      "outputs": [],
      "source": [
        "def get_end_marker(start_index):\n",
        "  for end_marker in end_markers:\n",
        "    if end_marker[\"index\"] > start_index:\n",
        "      return end_marker\n",
        "  end = len(lines.keys())\n",
        "  return {\n",
        "      \"index\": end,\n",
        "      \"before\": lines[end][\"before\"],\n",
        "      \"after\": lines[end][\"after\"],\n",
        "      \"text\": lines[end][\"text\"],\n",
        "  }\n",
        "\n",
        "cuts = []\n",
        "for start_marker in start_markers:\n",
        "  end_marker = get_end_marker(start_marker[\"index\"])\n",
        "  print(start_marker[\"before\"].replace(\",\",\".\"), start_marker[\"text\"], end_marker[\"after\"].replace(\",\",\".\"))\n",
        "  cuts.append({\n",
        "      \"before\": start_marker[\"before\"].replace(\",\",\".\"),\n",
        "      \"after\": end_marker[\"after\"].replace(\",\",\".\"),\n",
        "      \"text\": start_marker[\"text\"],      \n",
        "  })\n",
        "print(cuts)\n",
        "with open(f\"{RESULTSDIR}/cuts.json\", \"w\") as f:\n",
        "  json.dump(cuts, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ic77SiSF9Sr"
      },
      "source": [
        "Make the cuts with ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dPPek8uyIE3D"
      },
      "outputs": [],
      "source": [
        "import subprocess\n",
        "for index, cut in enumerate(cuts):\n",
        "  print(\"Processing cut\", index+1, \"of\", len(cuts))\n",
        "  subprocess.run([\n",
        "      \"ffmpeg\", \n",
        "      \"-i\",\n",
        "      INPUTVIDEO,\n",
        "      \"-ss\",\n",
        "      cut[\"before\"],\n",
        "      \"-to\",\n",
        "      cut[\"after\"],\n",
        "      \"-c:v\",\n",
        "      \"copy\",\n",
        "      \"-c:a\",\n",
        "      \"copy\",\n",
        "      f'{RESULTSDIR}/{index:0>2d}.{VIDEOFORMAT}'\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcmcgBi_61aH"
      },
      "source": [
        "Finally, move video to archive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IV8RJcwD637b"
      },
      "outputs": [],
      "source": [
        "!mv $INPUTVIDEO $ARCHIVEDIR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IzaVp6UQqLk"
      },
      "source": [
        "And disconnect the runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8j25YJXQsn9"
      },
      "outputs": [],
      "source": [
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
